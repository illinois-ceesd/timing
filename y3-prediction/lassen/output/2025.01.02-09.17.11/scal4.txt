Customizing shell for Lassen.

The following have been reloaded with a version change:
  1) base-gcc/8.3.1 => base-gcc/11.2.1


Due to MODULEPATH changes, the following have been reloaded:
  1) spectrum-mpi/rolling-release

The following have been reloaded with a version change:
  1) gcc/8.3.1 => gcc/10.2.1

Activating 'timing.pilot' environment for '/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/emirge/miniforge3/bin/conda'.
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/y3-prediction-scaling-run/scalability_test
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/y3-prediction-scaling-run/scalability_test
Driver directory: /p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/y3-prediction-scaling-run
Wed Jan  1 12:11:09 PST 2025
Running parallel timing tests...
* Running prediction-scalability test in scalability_test.
** Running prediction-scalability_np1 on 1 ranks.
++ runoptions='-n 1'
++ [[ ! -z '' ]]
++ jsrun -g 1 -a 1 -n 1 bash /p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/y3-prediction-scaling-run/emirge/mirgecom/scripts/lassen-parallel-spawner.sh python -u -O -m mpi4py driver.py -c prediction-scalability_np1 -g /p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/y3-prediction-scaling-run/scalability_test/log_data -i run_params_np1.yaml --log --lazy
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/emirge/miniforge3/envs/timing.pilot/bin/python: No module named mpi4py
++ return_code=1
++ set +x
mv: cannot stat ‘viz_data’: No such file or directory
mv: cannot stat ‘restart_data’: No such file or directory
**  scalability_test/prediction-scalability_np1 failed.
** Running prediction-scalability_np2 on 2 ranks.
++ runoptions='-n 2'
++ [[ ! -z '' ]]
++ jsrun -g 1 -a 1 -n 2 bash /p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/y3-prediction-scaling-run/emirge/mirgecom/scripts/lassen-parallel-spawner.sh python -u -O -m mpi4py driver.py -c prediction-scalability_np2 -g /p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/y3-prediction-scaling-run/scalability_test/log_data -i run_params_np2.yaml --log --lazy
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/emirge/miniforge3/envs/timing.pilot/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/emirge/miniforge3/envs/timing.pilot/bin/python: No module named mpi4py
++ return_code=1
++ set +x
mv: cannot stat ‘viz_data’: No such file or directory
mv: cannot stat ‘restart_data’: No such file or directory
**  scalability_test/prediction-scalability_np2 failed.
** Running prediction-scalability_np4 on 4 ranks.
++ runoptions='-n 4'
++ [[ ! -z '' ]]
++ jsrun -g 1 -a 1 -n 4 bash /p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/y3-prediction-scaling-run/emirge/mirgecom/scripts/lassen-parallel-spawner.sh python -u -O -m mpi4py driver.py -c prediction-scalability_np4 -g /p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/y3-prediction-scaling-run/scalability_test/log_data -i run_params_np4.yaml --log --lazy
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/emirge/miniforge3/envs/timing.pilot/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/emirge/miniforge3/envs/timing.pilot/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/emirge/miniforge3/envs/timing.pilot/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/emirge/miniforge3/envs/timing.pilot/bin/python: No module named mpi4py
++ return_code=1
++ set +x
mv: cannot stat ‘viz_data’: No such file or directory
mv: cannot stat ‘restart_data’: No such file or directory
**  scalability_test/prediction-scalability_np4 failed.
Wed Jan  1 12:11:15 PST 2025
Scaling/timing tests done.
Passing tests: 
Failing tests:  scalability_test/prediction-scalability_np1 scalability_test/prediction-scalability_np2 scalability_test/prediction-scalability_np4

------------------------------------------------------------
Sender: LSF System <lsfadmin@lassen710>
Subject: Job 6635013: <scale4> in cluster <lassen> Exited

Job <scale4> was submitted from host <lassen708> by user <mtcampbe> in cluster <lassen> at Wed Jan  1 12:10:57 2025
Job was executed on host(s) <1*lassen710>, in queue <pbatch>, as user <mtcampbe> in cluster <lassen> at Wed Jan  1 12:11:00 2025
                            <40*lassen65>
</g/g17/mtcampbe> was used as the home directory.
</p/gpfs1/mtcampbe/CEESD/AutomatedTesting/RepoMonitoring/pilot-timing/y3-prediction-scaling-run/scalability_test> was used as the working directory.
Started at Wed Jan  1 12:11:00 2025
Terminated at Wed Jan  1 12:11:15 2025
Results reported at Wed Jan  1 12:11:15 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
#BSUB -nnodes 1
#BSUB -G uiuc
#BSUB -W 180
#BSUB -J scale4
#BSUB -q pbatch
#BSUB -o scal4.txt

source ../emirge/config/activate_env.sh
source ../emirge/mirgecom/scripts/mirge-testing-env.sh
source ../scripts/multi_scalability.sh -p ../ -n 4



------------------------------------------------------------

Exited with exit code 3.

Resource usage summary:

    CPU time :                                   0.19 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   16 sec.
    Turnaround time :                            18 sec.

The output (if any) is above this job summary.

