Customizing shell for Lassen.
Activating 'flame1d.lazy.timing.env' environment for '/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/bin/conda'.
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/y3-prediction-scaling-run/scalability_test
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/y3-prediction-scaling-run/scalability_test
Driver directory: /p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/y3-prediction-scaling-run
Tue May 21 23:27:26 PDT 2024
Running parallel timing tests...
* Running prediction-scalability test in scalability_test.
** Running prediction-scalability_np32 on 32 ranks.
Making 3D mesh with the following parameters:
Output name: actii
Number of threads: 1
Mesh size: 9.535
Injector ratio: 2
Sample boundary layer ratio: 4
Bulk boundary layer ratio: 4
Injector boundary layer ratio: 2
Cavity boundary layer ratio: 2
Surround boundary layer ratio: 2
Isolator factor: 2
Cavity factor: 4
Injector factor: 3
Shear layer factor: 4
Sample factor: 4
Make link actii.msh for finished mesh.
Expected mesh file already exists, skipping mesh creation.
++ jsrun -g 1 -a 1 -n 32 bash /p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/y3-prediction-scaling-run/emirge/mirgecom/scripts/lassen-parallel-spawner.sh python -u -O -m mpi4py driver.py -c prediction-scalability_np32 -g /p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/y3-prediction-scaling-run/scalability_test/log_data -i run_params.yaml --log --lazy
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
/p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/emirge/miniforge3/envs/flame1d.lazy.timing.env/bin/python: No module named mpi4py
++ return_code=1
++ set +x
mv: cannot stat ‘viz_data’: No such file or directory
mv: cannot stat ‘restart_data’: No such file or directory
**  scalability_test/prediction-scalability_np32 failed.
Tue May 21 23:27:27 PDT 2024
Scaling/timing tests done.
Passing tests: 
Failing tests:  scalability_test/prediction-scalability_np32

------------------------------------------------------------
Sender: LSF System <lsfadmin@lassen710>
Subject: Job 5897386: <scale32> in cluster <lassen> Exited

Job <scale32> was submitted from host <lassen708> by user <mtcampbe> in cluster <lassen> at Tue May 21 23:23:55 2024
Job was executed on host(s) <1*lassen710>, in queue <pbatch>, as user <mtcampbe> in cluster <lassen> at Tue May 21 23:27:16 2024
                            <40*lassen465>
                            <40*lassen795>
                            <40*lassen138>
                            <40*lassen796>
                            <40*lassen798>
                            <40*lassen144>
                            <40*lassen315>
                            <40*lassen160>
</g/g17/mtcampbe> was used as the home directory.
</p/gpfs1/mtcampbe/CEESD/AutomatedTesting/MIRGE-Timing/timing/y3-prediction-scaling-run/scalability_test> was used as the working directory.
Started at Tue May 21 23:27:16 2024
Terminated at Tue May 21 23:27:27 2024
Results reported at Tue May 21 23:27:27 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
#BSUB -nnodes 8
#BSUB -G uiuc
#BSUB -W 120
#BSUB -J scale32
#BSUB -q pbatch
#BSUB -o scal32.txt

source ../emirge/config/activate_env.sh
source ../emirge/mirgecom/scripts/mirge-testing-env.sh
source ../scripts/multi_scalability.sh -p ../ -s 32 -n 32

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   0.21 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   11 sec.
    Turnaround time :                            212 sec.

The output (if any) is above this job summary.

